{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Script:\n",
    "#    testDecisionTree.py\n",
    "# Usage:\n",
    "#    python testDecisionTree.py\n",
    "# Description:\n",
    "#    Test the prediction model using test data set\n",
    "# Authors:\n",
    "#    Jackie Chu,   cchu@salesforce.com\n",
    "#    Jasmin Nakic, jnakic@salesforce.com\n",
    "#######################################################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Enable or disable debug printing\n",
    "debugFlag = False\n",
    "\n",
    "# Feature list\n",
    "perfCols = [\"PageTime_ms\",\"TotalServerTime_ms\",\"TotalBrowserTime_ms\",\"Action_count\",\"Api_count\",\"Db_count\",\"DbTime_ms\",\"Xhr_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a set of columns to the destination\n",
    "def addColumns(dest, src, colNames):\n",
    "    # Initialize temporary array\n",
    "    tmpArr = np.empty(src.shape[0])\n",
    "    cols = 0\n",
    "    # Copy column content\n",
    "    for name in colNames:\n",
    "        if cols == 0: # first column\n",
    "            tmpArr = np.copy(src[name])\n",
    "            tmpArr = np.reshape(tmpArr,(-1,1))\n",
    "        else:\n",
    "            tmpCol = np.copy(src[name])\n",
    "            tmpCol = np.reshape(tmpCol,(-1,1))\n",
    "            tmpArr = np.append(tmpArr,tmpCol,1)\n",
    "        cols = cols + 1\n",
    "    return np.append(dest,tmpArr,1)\n",
    "#end addColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get predictions using Decision Tree model\n",
    "def getPredictions(data,colList,modelName):\n",
    "    # Prepare the data for the model\n",
    "    X = np.zeros(data.shape[0])\n",
    "    X = np.reshape(X,(-1,1))\n",
    "    X = addColumns(X,data,colList)\n",
    "    if debugFlag:\n",
    "        print(\"X 0: \", X[0:5])\n",
    "    Y = np.copy(data[\"Status\"])\n",
    "    if debugFlag:\n",
    "        print(\"Y 0: \", Y[0:5])\n",
    "\n",
    "    modelFileName = modelName+\".model\"\n",
    "    model = joblib.load(modelFileName)\n",
    "\n",
    "    print(\"NAMES: \", data.dtype.names)\n",
    "    print(\"TREE: \", model.tree_)\n",
    "    print(\"MAX_DEPTH: \", model.tree_.max_depth)\n",
    "    print(\"NODE_COUNT: \", model.tree_.node_count)\n",
    "    print(\"CHILDREN_LEFT: \", model.tree_.children_left)\n",
    "    print(\"CHILDREN_RIGHT: \", model.tree_.children_left)\n",
    "    print(\"FEATURE: \", model.tree_.feature)\n",
    "    print(\"THRESHOLD: \", model.tree_.threshold)\n",
    "    print(\"FEATURE_IMPORTANCES: \", model.feature_importances_)\n",
    "    print(\"APPLY: \", model.apply(X[:1]))\n",
    "    print(\"DECISION PATH: \", model.decision_path(X[:1]))\n",
    "\n",
    "    P = model.predict(X)\n",
    "    print(\"SCORE values: \", model.score(X,Y))\n",
    "    if debugFlag:\n",
    "        print(\"P 0-5: \", P[0:5])\n",
    "\n",
    "    return P\n",
    "#end getPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write test results to a file\n",
    "def writeResult(output,data,p):\n",
    "    result = np.array(\n",
    "       np.empty(data.shape[0]),\n",
    "       dtype=[\n",
    "           (\"PageTime_ms\",int),\n",
    "           (\"TotalServerTime_ms\",int),\n",
    "           (\"TotalBrowserTime_ms\",int),\n",
    "           (\"Action_count\",int),\n",
    "           (\"Api_count\",int),\n",
    "           (\"Db_count\",int),\n",
    "           (\"DbTime_ms\",int),\n",
    "           (\"Xhr_count\",int),\n",
    "           (\"Status\",\"|U20\"),\n",
    "           (\"PREDICTION\",\"|U20\")\n",
    "        ]\n",
    "    )\n",
    "    result[\"PageTime_ms\"]     = data[\"PageTime_ms\"]\n",
    "    result[\"TotalServerTime_ms\"]     = data[\"TotalServerTime_ms\"]\n",
    "    result[\"TotalBrowserTime_ms\"]     = data[\"TotalBrowserTime_ms\"]\n",
    "    result[\"Action_count\"]     = data[\"Action_count\"]\n",
    "    result[\"Api_count\"]    = data[\"Api_count\"]\n",
    "    result[\"Db_count\"]    = data[\"Db_count\"]\n",
    "    result[\"DbTime_ms\"]    = data[\"DbTime_ms\"]\n",
    "    result[\"Xhr_count\"]    = data[\"Xhr_count\"]\n",
    "    result[\"Status\"] = data[\"Status\"]\n",
    "    result[\"PREDICTION\"] = p\n",
    "    if debugFlag:\n",
    "        print(\"R 0-5: \", result[0:5])\n",
    "    hdr = \"PageTime_ms,TotalServerTime_ms,TotalBrowserTime_ms,Action_count,Api_count,Db_count,DbTime_ms,Xhr_count,Status,PREDICTION\"\n",
    "    np.savetxt(output,result,fmt=\"%s\",delimiter=\",\",header=hdr,comments=\"\")\n",
    "#end writeResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start\n",
    "inputFileName = \"PerfRun_TestData.csv\"\n",
    "outputFileName = \"PerfRun_TestResult.txt\"\n",
    "modelName = \"PerfRun\"\n",
    "\n",
    "# All input columns - data types are strings, float and int\n",
    "testData = np.genfromtxt(\n",
    "    inputFileName,\n",
    "    delimiter=',',\n",
    "    names=True,\n",
    "    dtype=(\"|U20\",int,int,int,int,int,int,int,int)\n",
    ")\n",
    "if debugFlag:\n",
    "    print(\"testData 0: \", testData[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 0:  [[   0. 2198. 2041. 1709.   13.   52.  289.  502.   10.]\n",
      " [   0. 2204. 2023. 1679.   13.   50.  289.  525.   10.]\n",
      " [   0. 2723. 2182. 1944.   13.   50.  331.  472.   10.]\n",
      " [   0. 2402. 2178. 1716.   13.   52.  293.  511.   10.]\n",
      " [   0. 2323. 2199. 1675.   13.   54.  290.  491.   10.]]\n",
      "Y 0:  ['Success' 'Success' 'Invalid' 'Success' 'Success']\n",
      "NAMES:  ('Status', 'PageTime_ms', 'TotalServerTime_ms', 'TotalBrowserTime_ms', 'Action_count', 'Api_count', 'Db_count', 'DbTime_ms', 'Xhr_count')\n",
      "TREE:  <sklearn.tree._tree.Tree object at 0x1a0b2e2308>\n",
      "MAX_DEPTH:  3\n",
      "NODE_COUNT:  15\n",
      "CHILDREN_LEFT:  [ 1  2  3 -1 -1  6 -1 -1  9 10 -1 -1 13 -1 -1]\n",
      "CHILDREN_RIGHT:  [ 1  2  3 -1 -1  6 -1 -1  9 10 -1 -1 13 -1 -1]\n",
      "FEATURE:  [ 1  4  1 -2 -2  2 -2 -2  7  3 -2 -2  1 -2 -2]\n",
      "THRESHOLD:  [ 2.4995e+03  1.2500e+01  2.0075e+03 -2.0000e+00 -2.0000e+00  2.6170e+03\n",
      " -2.0000e+00 -2.0000e+00  3.7750e+02  1.6930e+03 -2.0000e+00 -2.0000e+00\n",
      "  2.7245e+03 -2.0000e+00 -2.0000e+00]\n",
      "SCORE values:  0.6656346749226006\n",
      "SCORE values:  0.6656346749226006\n",
      "P 0-5:  ['Success' 'Success' 'Regression' 'Success' 'Success']\n"
     ]
    }
   ],
   "source": [
    "# Get Prediction for PerfRun_TestData.csv\n",
    "P = getPredictions(testData,perfCols,modelName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 0-5:  [('52.0', 2198, 2041, 1709, 13, 52, 289, 502, 10, 'Success', 'Success')\n",
      " ('285.0', 2204, 2023, 1679, 13, 50, 289, 525, 10, 'Success', 'Success')\n",
      " ('5.5265081749e-313', 2723, 2182, 1944, 13, 50, 331, 472, 10, 'Invalid', 'Regression')\n",
      " ('0.0', 2402, 2178, 1716, 13, 52, 293, 511, 10, 'Success', 'Success')\n",
      " ('2.67e-322', 2323, 2199, 1675, 13, 54, 290, 491, 10, 'Success', 'Success')]\n"
     ]
    }
   ],
   "source": [
    "# Write result to file PerfRun_TestResult.txt\n",
    "writeResult(outputFileName,testData,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

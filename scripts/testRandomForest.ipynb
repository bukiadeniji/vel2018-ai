{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Script:\n",
    "#    testRandomForest.py\n",
    "# Usage:\n",
    "#    python testRandomForest.py\n",
    "# Description:\n",
    "#    Test the prediction model using test data set\n",
    "# Authors:\n",
    "#    Jackie Chu,   cchu@salesforce.com\n",
    "#    Jasmin Nakic, jnakic@salesforce.com\n",
    "#######################################################\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# Enable or disable debug printing\n",
    "debugFlag = True\n",
    "\n",
    "# Feature list\n",
    "perfCols = [\"PageTime_ms\",\"TotalServerTime_ms\",\"TotalBrowserTime_ms\",\"Action_count\",\"Api_count\",\"Db_count\",\"DbTime_ms\",\"Xhr_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumns(dest, src, colNames):\n",
    "    # Initialize temporary array\n",
    "    tmpArr = np.empty(src.shape[0])\n",
    "    cols = 0\n",
    "    # Copy column content\n",
    "    for name in colNames:\n",
    "        if cols == 0: # first column\n",
    "            tmpArr = np.copy(src[name])\n",
    "            tmpArr = np.reshape(tmpArr,(-1,1))\n",
    "        else:\n",
    "            tmpCol = np.copy(src[name])\n",
    "            tmpCol = np.reshape(tmpCol,(-1,1))\n",
    "            tmpArr = np.append(tmpArr,tmpCol,1)\n",
    "        cols = cols + 1\n",
    "    return np.append(dest,tmpArr,1)\n",
    "#end addColumns\n",
    "\n",
    "def getPredictions(data,colList,modelName):\n",
    "    # Prepare the data for the model\n",
    "    X = np.zeros(data.shape[0])\n",
    "    X = np.reshape(X,(-1,1))\n",
    "    X = addColumns(X,data,colList)\n",
    "    if debugFlag:\n",
    "        print(\"X 0: \", X[0:5])\n",
    "    Y = np.copy(data[\"Status\"])\n",
    "    if debugFlag:\n",
    "        print(\"Y 0: \", Y[0:5])\n",
    "\n",
    "    modelFileName = modelName+\".model\"\n",
    "    model = joblib.load(modelFileName)\n",
    "\n",
    "    print(\"MODEL: \", model)\n",
    "    print(\"NAMES: \", data.dtype.names)\n",
    "    print(\"FEATURE_IMPORTANCES: \", model.feature_importances_)\n",
    "    print(\"N_FEATURES: \", model.n_features_)\n",
    "    print(\"N_OUTPUTS: \", model.n_outputs_)\n",
    "    print(\"OOB_DECISION_FUNCTION: \", model.oob_decision_function_)\n",
    "    print(\"OOB_SCORE: \", model.oob_score_)\n",
    "\n",
    "    P = model.predict(X)\n",
    "    print(\"SCORE values: \", model.score(X,Y))\n",
    "    if debugFlag:\n",
    "        print(\"P 0-5: \", P[0:5])\n",
    "\n",
    "    return P\n",
    "#end getPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResult(output,data,p):\n",
    "    result = np.array(\n",
    "       np.empty(data.shape[0]),\n",
    "       dtype=[\n",
    "           (\"Page\",\"|U20\"),\n",
    "           (\"PageTime_ms\",int),\n",
    "           (\"TotalServerTime_ms\",int),\n",
    "           (\"TotalBrowserTime_ms\",int),\n",
    "           (\"Action_count\",int),\n",
    "           (\"Api_count\",int),\n",
    "           (\"Db_count\",int),\n",
    "           (\"DbTime_ms\",int),\n",
    "           (\"Xhr_count\",int),\n",
    "           (\"Status\",\"|U20\"),\n",
    "           (\"PREDICTION\",\"|U20\")\n",
    "        ]\n",
    "    )\n",
    "    result[\"PageTime_ms\"]     = data[\"PageTime_ms\"]\n",
    "    result[\"TotalServerTime_ms\"]     = data[\"TotalServerTime_ms\"]\n",
    "    result[\"TotalBrowserTime_ms\"]     = data[\"TotalBrowserTime_ms\"]\n",
    "    result[\"Action_count\"]     = data[\"Action_count\"]\n",
    "    result[\"Api_count\"]    = data[\"Api_count\"]\n",
    "    result[\"Db_count\"]    = data[\"Db_count\"]\n",
    "    result[\"DbTime_ms\"]    = data[\"DbTime_ms\"]\n",
    "    result[\"Xhr_count\"]    = data[\"Xhr_count\"]\n",
    "    result[\"Status\"] = data[\"Status\"]\n",
    "    result[\"PREDICTION\"] = p\n",
    "    hdr = \"PageTime_ms,TotalServerTime_ms,TotalBrowserTime_ms,Action_count,Api_count,Db_count,DbTime_ms,Xhr_count,Status,PREDICTION\"\n",
    "    if debugFlag:\n",
    "        print(hdr)\n",
    "        print(\"R 0-5: \", result[0:5])\n",
    "    np.savetxt(output,result,fmt=\"%s\",delimiter=\",\",header=hdr,comments=\"\")\n",
    "#end writeResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testData :  [('Success', 2198, 2041, 1709, 13, 52, 289, 502, 10)\n",
      " ('Success', 2204, 2023, 1679, 13, 50, 289, 525, 10)\n",
      " ('Invalid', 2723, 2182, 1944, 13, 50, 331, 472, 10)\n",
      " ('Success', 2402, 2178, 1716, 13, 52, 293, 511, 10)\n",
      " ('Success', 2323, 2199, 1675, 13, 54, 290, 491, 10)]\n"
     ]
    }
   ],
   "source": [
    "# Start\n",
    "inputFileName = \"PerfRun_TestData.csv\"\n",
    "outputFileName = \"PerfRun_TestResult.txt\"\n",
    "modelName = \"PerfRandomForest\"\n",
    "\n",
    "# All input columns - data types are strings, float and int\n",
    "testData = np.genfromtxt(\n",
    "    inputFileName,\n",
    "    delimiter=',',\n",
    "    names=True,\n",
    "    dtype=(\"|U20\",int,int,int,int,int,int,int,int)\n",
    ")\n",
    "if debugFlag:\n",
    "    print(\"testData : \", testData[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 0:  [[   0. 2198. 2041. 1709.   13.   52.  289.  502.   10.]\n",
      " [   0. 2204. 2023. 1679.   13.   50.  289.  525.   10.]\n",
      " [   0. 2723. 2182. 1944.   13.   50.  331.  472.   10.]\n",
      " [   0. 2402. 2178. 1716.   13.   52.  293.  511.   10.]\n",
      " [   0. 2323. 2199. 1675.   13.   54.  290.  491.   10.]]\n",
      "Y 0:  ['Success' 'Success' 'Invalid' 'Success' 'Success']\n",
      "MODEL:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
      "NAMES:  ('Status', 'PageTime_ms', 'TotalServerTime_ms', 'TotalBrowserTime_ms', 'Action_count', 'Api_count', 'Db_count', 'DbTime_ms', 'Xhr_count')\n",
      "FEATURE_IMPORTANCES:  [0.         0.38268979 0.16536471 0.14094058 0.03812361 0.03793318\n",
      " 0.08351512 0.13628765 0.01514536]\n",
      "N_FEATURES:  9\n",
      "N_OUTPUTS:  1\n",
      "OOB_DECISION_FUNCTION:  [[0.         0.66666667 0.         0.33333333]\n",
      " [0.         0.         0.         1.        ]\n",
      " [0.         0.         1.         0.        ]\n",
      " ...\n",
      " [0.         0.         1.         0.        ]\n",
      " [0.         0.33333333 0.66666667 0.        ]\n",
      " [0.         0.         0.         1.        ]]\n",
      "OOB_SCORE:  0.6964423820572312\n",
      "SCORE values:  0.7647058823529411\n",
      "P 0-5:  ['Success' 'Success' 'Invalid' 'Invalid' 'Success']\n"
     ]
    }
   ],
   "source": [
    "# Get Prediction for PerfRun_TestData.csv\n",
    "P = getPredictions(testData,perfCols,modelName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageTime_ms,TotalServerTime_ms,TotalBrowserTime_ms,Action_count,Api_count,Db_count,DbTime_ms,Xhr_count,Status,PREDICTION\n",
      "R 0-5:  [('0.0', 2198, 2041, 1709, 13, 52, 289, 502, 10, 'Success', 'Success')\n",
      " ('4.4e-323', 2204, 2023, 1679, 13, 50, 289, 525, 10, 'Success', 'Success')\n",
      " ('0.0', 2723, 2182, 1944, 13, 50, 331, 472, 10, 'Invalid', 'Invalid')\n",
      " ('nan', 2402, 2178, 1716, 13, 52, 293, 511, 10, 'Success', 'Invalid')\n",
      " ('9.0', 2323, 2199, 1675, 13, 54, 290, 491, 10, 'Success', 'Success')]\n"
     ]
    }
   ],
   "source": [
    "# Write result to file PerfRun_TestResult.txt\n",
    "writeResult(outputFileName,testData,P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
